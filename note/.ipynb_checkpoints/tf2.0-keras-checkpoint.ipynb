{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:13:50.494677Z",
     "start_time": "2020-11-18T06:13:46.190525Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:13:50.516850Z",
     "start_time": "2020-11-18T06:13:50.509848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:13:55.854129Z",
     "start_time": "2020-11-18T06:13:55.559863Z"
    }
   },
   "outputs": [],
   "source": [
    "#读取模型\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "# help(fashion_mnist.load_data)\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() # 下载后的数据集放在 ~/.keras/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:13:58.626940Z",
     "start_time": "2020-11-18T06:13:58.623068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获得图片大小\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:14:01.765512Z",
     "start_time": "2020-11-18T06:14:01.526105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#打印图例\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plotImages(train_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:14:08.449623Z",
     "start_time": "2020-11-18T06:14:08.169056Z"
    }
   },
   "outputs": [],
   "source": [
    "#归一化\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:14:10.451600Z",
     "start_time": "2020-11-18T06:14:10.447925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始模型操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T06:24:58.592839Z",
     "start_time": "2020-11-10T06:24:43.646510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100352    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,642\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 100,352\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.9983 - accuracy: 0.7577 - val_loss: 0.6063 - val_accuracy: 0.8397\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.5571 - accuracy: 0.8478 - val_loss: 0.4867 - val_accuracy: 0.8593\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.4796 - accuracy: 0.8627 - val_loss: 0.4404 - val_accuracy: 0.8732\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 709us/step - loss: 0.4441 - accuracy: 0.8716 - val_loss: 0.4187 - val_accuracy: 0.8789\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.4234 - accuracy: 0.8760 - val_loss: 0.4010 - val_accuracy: 0.8819\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 679us/step - loss: 0.4097 - accuracy: 0.8790 - val_loss: 0.3909 - val_accuracy: 0.8858\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 683us/step - loss: 0.3997 - accuracy: 0.8815 - val_loss: 0.3835 - val_accuracy: 0.8884\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 667us/step - loss: 0.3926 - accuracy: 0.8836 - val_loss: 0.3790 - val_accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 705us/step - loss: 0.3870 - accuracy: 0.8846 - val_loss: 0.3734 - val_accuracy: 0.8898\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 724us/step - loss: 0.3823 - accuracy: 0.8853 - val_loss: 0.3700 - val_accuracy: 0.8916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16dce74a8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#全链接层模型\n",
    "# see: https://blog.csdn.net/weixin_42483560/article/details/84951612\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', use_bias=False, trainable=False), #全连接层\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "#模型总结\n",
    "model.summary()\n",
    "#编译 要先这一步才能进行训练\n",
    "model.compile(optimizer='adam',\n",
    "      loss='sparse_categorical_crossentropy', #categorical_crossentropy->[1,0,0,0,0]\n",
    "      metrics=['accuracy']) \n",
    "      \n",
    "#训练\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T06:27:19.930330Z",
     "start_time": "2020-11-10T06:27:19.921798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 128) dtype=float32, numpy=\n",
       " array([[ 0.02997167,  0.01067434, -0.06321626, ..., -0.0218691 ,\n",
       "         -0.03136409,  0.07608006],\n",
       "        [ 0.07777431, -0.06751747,  0.00930348, ..., -0.02662834,\n",
       "          0.03385767, -0.07503352],\n",
       "        [ 0.06498899,  0.06744405, -0.00157072, ..., -0.04843459,\n",
       "          0.07320272, -0.06790884],\n",
       "        ...,\n",
       "        [-0.07329933,  0.00676517, -0.01012445, ..., -0.04616012,\n",
       "          0.02187999, -0.0672981 ],\n",
       "        [ 0.07224391, -0.08051819,  0.00165532, ...,  0.03741685,\n",
       "         -0.05376539, -0.05330751],\n",
       "        [-0.0607429 ,  0.00741481, -0.02320548, ...,  0.06338764,\n",
       "         -0.06856947, -0.06819692]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(128, 10) dtype=float32, numpy=\n",
       " array([[-1.8142213e+00,  4.2992854e-01,  1.2543461e+00, ...,\n",
       "          3.8683903e-01, -5.3497076e-01, -4.3163979e-01],\n",
       "        [ 1.1057474e-01,  1.1619552e+00, -1.0981963e+00, ...,\n",
       "         -1.4094307e-01, -1.8719062e+00, -9.7784692e-01],\n",
       "        [ 5.0942272e-01, -8.6876892e-02,  2.6603925e-01, ...,\n",
       "         -4.4376794e-01,  2.7018338e-01, -1.0330306e-01],\n",
       "        ...,\n",
       "        [ 1.1521474e+00, -2.6069963e+00, -1.2756586e+00, ...,\n",
       "          2.3897278e+00, -1.3205816e-01,  4.0890768e-01],\n",
       "        [ 4.2220777e-01,  1.1883215e+00, -2.1380545e-03, ...,\n",
       "         -5.6941044e-01, -9.2231822e-01, -5.3413647e-01],\n",
       "        [-5.7547212e-01, -1.3838303e+00,  5.5691904e-01, ...,\n",
       "         -1.5512843e+00, -9.2491579e-01,  4.1451283e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.33477652,  1.0386319 , -0.24291997, -0.38652238, -0.1374207 ,\n",
       "         0.6989667 , -0.05697611,  0.49339765, -1.123026  ,  0.21202369],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型权重\n",
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T07:49:53.873180Z",
     "start_time": "2020-11-10T07:49:53.794570Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存权重\n",
    "model.save_weights('./fashion_mnist/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复权重\n",
    "model.load_weights('./fashion_mnist/my_checkpoint')\n",
    "# model1.load_weights('./fashion_mnist/my_checkpoint') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T07:50:44.103420Z",
     "start_time": "2020-11-10T07:50:43.754828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3700 - accuracy: 0.8916\n",
      "Restored model, accuracy: 89.16%\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存整个模型\n",
    "model.save('my_model.h5')\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:11:32.285161Z",
     "start_time": "2020-11-10T08:11:32.265673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# 在文件名中包含 epoch (使用 `str.format`)\n",
    "checkpoint_path = \"fashion_mnist_1/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# 创建一个回调，每个epoch保存模型的权重\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    period=1) #save_freq = ‘epoch'/n samples 60000 100 600\n",
    "\n",
    "# 使用 `checkpoint_path` 格式保存权重\n",
    "model.save_weights(checkpoint_path.format(epoch=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:12:31.925497Z",
     "start_time": "2020-11-10T08:12:24.246499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 848us/step - loss: 0.3786 - accuracy: 0.8859 - val_loss: 0.3677 - val_accuracy: 0.8926.3807 - accu\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 725us/step - loss: 0.3754 - accuracy: 0.8875 - val_loss: 0.3654 - val_accuracy: 0.8919\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 719us/step - loss: 0.3728 - accuracy: 0.8878 - val_loss: 0.3637 - val_accuracy: 0.8920\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 718us/step - loss: 0.3706 - accuracy: 0.8890 - val_loss: 0.3622 - val_accuracy: 0.8923\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 723us/step - loss: 0.3685 - accuracy: 0.8889 - val_loss: 0.3629 - val_accuracy: 0.8918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142810908>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用新的回调训练模型,并保存模型权重\n",
    "model.fit(train_images, \n",
    "              train_labels,\n",
    "              epochs=5, \n",
    "              callbacks=[cp_callback],\n",
    "              validation_data=(test_images,test_labels))\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:54:49.622249Z",
     "start_time": "2020-11-10T08:54:49.618936Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN的输入则是一个三维神经元,所以我们这边填充一层，使其变成3维\n",
    "train_images = train_images[..., tf.newaxis]\n",
    "test_images = test_images[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T08:54:51.068370Z",
     "start_time": "2020-11-10T08:54:51.064408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T09:08:15.872624Z",
     "start_time": "2020-11-10T09:04:32.107048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.1610 - accuracy: 0.9507 - val_loss: 0.0434 - val_accuracy: 0.9869\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.0425 - val_accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0289 - val_accuracy: 0.9908\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0242 - val_accuracy: 0.9925\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0289 - val_accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0270 - val_accuracy: 0.9911\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0251 - val_accuracy: 0.9937\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0342 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0329 - val_accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0335 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14291f940>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "model1.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) #卷基层\n",
    "model1.add(tf.keras.layers.MaxPooling2D((2, 2))) #池化层\n",
    "model1.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model1.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。\n",
    "# see https://blog.csdn.net/program_developer/article/details/80853425\n",
    "model1.add(tf.keras.layers.Flatten())\n",
    "model1.add(tf.keras.layers.Dense(256, activation='relu')) #全连接层\n",
    "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy VS. sparse_categorical_crossentropy 的区别\n",
    "# https://blog.csdn.net/qq_42961707/article/details/95799706\n",
    "model1.compile(optimizer='adam',\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "      \n",
    "model1.fit(train_images, train_labels, \n",
    "           batch_size=64,\n",
    "           epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T10:25:28.793189Z",
     "start_time": "2020-11-10T10:25:27.691935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0335 - accuracy: 0.9917\n",
      "Restored model, accuracy: 99.17%\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "loss,acc = model1.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:18:26.204833Z",
     "start_time": "2020-11-18T06:18:26.201028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape (60000, 28, 28)\n",
      "test_images shape (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_images shape\", train_images.shape)\n",
    "print(\"test_images shape\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:18:42.022714Z",
     "start_time": "2020-11-18T06:18:42.018411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images2 shape (60000, 28, 28)\n",
      "test_images2 shape (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_images2 = train_images.reshape((60000, 28, 28))\n",
    "print(\"train_images2 shape\", train_images2.shape)\n",
    "test_images2 = test_images.reshape((10000, 28, 28))\n",
    "print(\"test_images2 shape\", test_images2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:22:43.617183Z",
     "start_time": "2020-11-18T06:18:55.120735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3529 - accuracy: 0.8852 - val_loss: 0.1481 - val_accuracy: 0.9505\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1035 - accuracy: 0.9689 - val_loss: 0.0935 - val_accuracy: 0.9717\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0708 - accuracy: 0.9788 - val_loss: 0.0964 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0549 - accuracy: 0.9830 - val_loss: 0.0560 - val_accuracy: 0.9814\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0455 - val_accuracy: 0.9860\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0377 - accuracy: 0.9886 - val_loss: 0.0467 - val_accuracy: 0.9853\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0477 - val_accuracy: 0.9834\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.0363 - val_accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0380 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0399 - val_accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x169013630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RNN\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.LSTM(128,input_shape=(None,28))) # batchsize,28,28\n",
    "# model2.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "#(hidden size * (hidden size + input_dim ) + hidden size) *4\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model2.fit(train_images2, train_labels, epochs=10, validation_data=(test_images2, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T06:34:20.548313Z",
     "start_time": "2020-11-18T06:34:19.017162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0399 - accuracy: 0.9875\n",
      "Restored model2, accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "loss2,acc2 = model2.evaluate(test_images2,  test_labels, verbose=2)\n",
    "print(\"Restored model2, accuracy: {:5.2f}%\".format(100*acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
